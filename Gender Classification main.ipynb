{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ACER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 300/74059 [00:07<29:15, 42.02it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m file \u001b[39m=\u001b[39m BASE_DIR \u001b[39m+\u001b[39m df\u001b[39m.\u001b[39mloc[i, \u001b[39m'\u001b[39m\u001b[39mfilename\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     10\u001b[0m wf, sr \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39mload(file)\n\u001b[1;32m---> 11\u001b[0m mfcc_wf \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39;49mfeature\u001b[39m.\u001b[39;49mmfcc(y\u001b[39m=\u001b[39;49mwf, sr\u001b[39m=\u001b[39;49msr)\n\u001b[0;32m     12\u001b[0m b \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mpad_sequences(mfcc_wf, padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m'\u001b[39m, maxlen\u001b[39m=\u001b[39m\u001b[39m200\u001b[39m)\n\u001b[0;32m     13\u001b[0m X_train\u001b[39m.\u001b[39mappend(b)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\librosa\\feature\\spectral.py:1989\u001b[0m, in \u001b[0;36mmfcc\u001b[1;34m(y, sr, S, n_mfcc, dct_type, norm, lifter, **kwargs)\u001b[0m\n\u001b[0;32m   1843\u001b[0m \u001b[39m\"\"\"Mel-frequency cepstral coefficients (MFCCs)\u001b[39;00m\n\u001b[0;32m   1844\u001b[0m \n\u001b[0;32m   1845\u001b[0m \u001b[39m.. warning:: If multi-channel audio input ``y`` is provided, the MFCC\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1985\u001b[0m \u001b[39m>>> fig.colorbar(img2, ax=[ax[1]])\u001b[39;00m\n\u001b[0;32m   1986\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1987\u001b[0m \u001b[39mif\u001b[39;00m S \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1988\u001b[0m     \u001b[39m# multichannel behavior may be different due to relative noise floor differences between channels\u001b[39;00m\n\u001b[1;32m-> 1989\u001b[0m     S \u001b[39m=\u001b[39m power_to_db(melspectrogram(y\u001b[39m=\u001b[39my, sr\u001b[39m=\u001b[39msr, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs))\n\u001b[0;32m   1991\u001b[0m M: np\u001b[39m.\u001b[39mndarray \u001b[39m=\u001b[39m scipy\u001b[39m.\u001b[39mfftpack\u001b[39m.\u001b[39mdct(S, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m, \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39mdct_type, norm\u001b[39m=\u001b[39mnorm)[\n\u001b[0;32m   1992\u001b[0m     \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, :n_mfcc, :\n\u001b[0;32m   1993\u001b[0m ]\n\u001b[0;32m   1995\u001b[0m \u001b[39mif\u001b[39;00m lifter \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1996\u001b[0m     \u001b[39m# shape lifter for broadcasting\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\librosa\\feature\\spectral.py:2145\u001b[0m, in \u001b[0;36mmelspectrogram\u001b[1;34m(y, sr, S, n_fft, hop_length, win_length, window, center, pad_mode, power, **kwargs)\u001b[0m\n\u001b[0;32m   2142\u001b[0m \u001b[39m# Build a Mel filter\u001b[39;00m\n\u001b[0;32m   2143\u001b[0m mel_basis \u001b[39m=\u001b[39m filters\u001b[39m.\u001b[39mmel(sr\u001b[39m=\u001b[39msr, n_fft\u001b[39m=\u001b[39mn_fft, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m-> 2145\u001b[0m melspec: np\u001b[39m.\u001b[39mndarray \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49meinsum(\u001b[39m\"\u001b[39;49m\u001b[39m...ft,mf->...mt\u001b[39;49m\u001b[39m\"\u001b[39;49m, S, mel_basis, optimize\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m   2146\u001b[0m \u001b[39mreturn\u001b[39;00m melspec\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\core\\einsumfunc.py:1419\u001b[0m, in \u001b[0;36meinsum\u001b[1;34m(out, optimize, *operands, **kwargs)\u001b[0m\n\u001b[0;32m   1416\u001b[0m     right_pos\u001b[39m.\u001b[39mappend(input_right\u001b[39m.\u001b[39mfind(s))\n\u001b[0;32m   1418\u001b[0m \u001b[39m# Contract!\u001b[39;00m\n\u001b[1;32m-> 1419\u001b[0m new_view \u001b[39m=\u001b[39m tensordot(\u001b[39m*\u001b[39;49mtmp_operands, axes\u001b[39m=\u001b[39;49m(\u001b[39mtuple\u001b[39;49m(left_pos), \u001b[39mtuple\u001b[39;49m(right_pos)))\n\u001b[0;32m   1421\u001b[0m \u001b[39m# Build a new view if needed\u001b[39;00m\n\u001b[0;32m   1422\u001b[0m \u001b[39mif\u001b[39;00m (tensor_result \u001b[39m!=\u001b[39m results_index) \u001b[39mor\u001b[39;00m handle_out:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\core\\numeric.py:1121\u001b[0m, in \u001b[0;36mtensordot\u001b[1;34m(a, b, axes)\u001b[0m\n\u001b[0;32m   1119\u001b[0m at \u001b[39m=\u001b[39m a\u001b[39m.\u001b[39mtranspose(newaxes_a)\u001b[39m.\u001b[39mreshape(newshape_a)\n\u001b[0;32m   1120\u001b[0m bt \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39mtranspose(newaxes_b)\u001b[39m.\u001b[39mreshape(newshape_b)\n\u001b[1;32m-> 1121\u001b[0m res \u001b[39m=\u001b[39m dot(at, bt)\n\u001b[0;32m   1122\u001b[0m \u001b[39mreturn\u001b[39;00m res\u001b[39m.\u001b[39mreshape(olda \u001b[39m+\u001b[39m oldb)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Reading the CSV file\n",
    "df = pd.read_csv('cv-valid-train.csv')\n",
    "df = df[~df['gender'].isna()]\n",
    "\n",
    "BASE_DIR = 'cv-valid-train/'\n",
    "X_train, y_train = [], []\n",
    "\n",
    "for i in tqdm(df.index):\n",
    "    file = BASE_DIR + df.loc[i, 'filename']\n",
    "    wf, sr = librosa.load(file)\n",
    "    mfcc_wf = librosa.feature.mfcc(y=wf, sr=sr)\n",
    "    b = tf.keras.utils.pad_sequences(mfcc_wf, padding='post', maxlen=200)\n",
    "    X_train.append(b)\n",
    "    if df.loc[i, 'gender'] == 'male':\n",
    "        y_train.append(1)\n",
    "    else:\n",
    "        y_train.append(0)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cv-valid-train.csv')\n",
    "df = df[~df['gender'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74059, 8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accent</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cv-valid-train/sample-000005.mp3</td>\n",
       "      <td>a shepherd may like to travel but he should ne...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>female</td>\n",
       "      <td>us</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cv-valid-train/sample-000008.mp3</td>\n",
       "      <td>put jackie right on the staff</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>seventies</td>\n",
       "      <td>male</td>\n",
       "      <td>us</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cv-valid-train/sample-000013.mp3</td>\n",
       "      <td>but he had found a guide and didn't want to mi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>thirties</td>\n",
       "      <td>female</td>\n",
       "      <td>us</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cv-valid-train/sample-000014.mp3</td>\n",
       "      <td>as they began to decorate the hallway a silhou...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sixties</td>\n",
       "      <td>male</td>\n",
       "      <td>england</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cv-valid-train/sample-000019.mp3</td>\n",
       "      <td>then they got ahold of some dough and went goofy</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>fifties</td>\n",
       "      <td>male</td>\n",
       "      <td>australia</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195766</th>\n",
       "      <td>cv-valid-train/sample-195766.mp3</td>\n",
       "      <td>but before i go i want to tell you a little story</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>fourties</td>\n",
       "      <td>male</td>\n",
       "      <td>england</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195767</th>\n",
       "      <td>cv-valid-train/sample-195767.mp3</td>\n",
       "      <td>down below in the darkness were hundreds of pe...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>thirties</td>\n",
       "      <td>female</td>\n",
       "      <td>us</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195770</th>\n",
       "      <td>cv-valid-train/sample-195770.mp3</td>\n",
       "      <td>he heard a muffled grating sound and saw the b...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>england</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195771</th>\n",
       "      <td>cv-valid-train/sample-195771.mp3</td>\n",
       "      <td>the englishman said nothing</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>thirties</td>\n",
       "      <td>male</td>\n",
       "      <td>england</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195774</th>\n",
       "      <td>cv-valid-train/sample-195774.mp3</td>\n",
       "      <td>the phone rang while she was awake</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>us</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74059 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                filename   \n",
       "5       cv-valid-train/sample-000005.mp3  \\\n",
       "8       cv-valid-train/sample-000008.mp3   \n",
       "13      cv-valid-train/sample-000013.mp3   \n",
       "14      cv-valid-train/sample-000014.mp3   \n",
       "19      cv-valid-train/sample-000019.mp3   \n",
       "...                                  ...   \n",
       "195766  cv-valid-train/sample-195766.mp3   \n",
       "195767  cv-valid-train/sample-195767.mp3   \n",
       "195770  cv-valid-train/sample-195770.mp3   \n",
       "195771  cv-valid-train/sample-195771.mp3   \n",
       "195774  cv-valid-train/sample-195774.mp3   \n",
       "\n",
       "                                                     text  up_votes   \n",
       "5       a shepherd may like to travel but he should ne...         1  \\\n",
       "8                           put jackie right on the staff         3   \n",
       "13      but he had found a guide and didn't want to mi...         1   \n",
       "14      as they began to decorate the hallway a silhou...         1   \n",
       "19       then they got ahold of some dough and went goofy         1   \n",
       "...                                                   ...       ...   \n",
       "195766  but before i go i want to tell you a little story         1   \n",
       "195767  down below in the darkness were hundreds of pe...         3   \n",
       "195770  he heard a muffled grating sound and saw the b...         4   \n",
       "195771                        the englishman said nothing         1   \n",
       "195774                 the phone rang while she was awake         2   \n",
       "\n",
       "        down_votes        age  gender     accent  duration  \n",
       "5                0   twenties  female         us       NaN  \n",
       "8                0  seventies    male         us       NaN  \n",
       "13               0   thirties  female         us       NaN  \n",
       "14               0    sixties    male    england       NaN  \n",
       "19               0    fifties    male  australia       NaN  \n",
       "...            ...        ...     ...        ...       ...  \n",
       "195766           0   fourties    male    england       NaN  \n",
       "195767           0   thirties  female         us       NaN  \n",
       "195770           0   twenties    male    england       NaN  \n",
       "195771           0   thirties    male    england       NaN  \n",
       "195774           0   twenties    male         us       NaN  \n",
       "\n",
       "[74059 rows x 8 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1=df1.drop(['text'],axis=1)\n",
    "df1=df1.drop(['up_votes'],axis=1)\n",
    "df1=df1.drop(['down_votes'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df1.drop(['duration'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cv-valid-train/sample-000005.mp3</td>\n",
       "      <td>twenties</td>\n",
       "      <td>female</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cv-valid-train/sample-000008.mp3</td>\n",
       "      <td>seventies</td>\n",
       "      <td>male</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cv-valid-train/sample-000013.mp3</td>\n",
       "      <td>thirties</td>\n",
       "      <td>female</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cv-valid-train/sample-000014.mp3</td>\n",
       "      <td>sixties</td>\n",
       "      <td>male</td>\n",
       "      <td>england</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cv-valid-train/sample-000019.mp3</td>\n",
       "      <td>fifties</td>\n",
       "      <td>male</td>\n",
       "      <td>australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195766</th>\n",
       "      <td>cv-valid-train/sample-195766.mp3</td>\n",
       "      <td>fourties</td>\n",
       "      <td>male</td>\n",
       "      <td>england</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195767</th>\n",
       "      <td>cv-valid-train/sample-195767.mp3</td>\n",
       "      <td>thirties</td>\n",
       "      <td>female</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195770</th>\n",
       "      <td>cv-valid-train/sample-195770.mp3</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>england</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195771</th>\n",
       "      <td>cv-valid-train/sample-195771.mp3</td>\n",
       "      <td>thirties</td>\n",
       "      <td>male</td>\n",
       "      <td>england</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195774</th>\n",
       "      <td>cv-valid-train/sample-195774.mp3</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74059 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                filename        age  gender     accent\n",
       "5       cv-valid-train/sample-000005.mp3   twenties  female         us\n",
       "8       cv-valid-train/sample-000008.mp3  seventies    male         us\n",
       "13      cv-valid-train/sample-000013.mp3   thirties  female         us\n",
       "14      cv-valid-train/sample-000014.mp3    sixties    male    england\n",
       "19      cv-valid-train/sample-000019.mp3    fifties    male  australia\n",
       "...                                  ...        ...     ...        ...\n",
       "195766  cv-valid-train/sample-195766.mp3   fourties    male    england\n",
       "195767  cv-valid-train/sample-195767.mp3   thirties  female         us\n",
       "195770  cv-valid-train/sample-195770.mp3   twenties    male    england\n",
       "195771  cv-valid-train/sample-195771.mp3   thirties    male    england\n",
       "195774  cv-valid-train/sample-195774.mp3   twenties    male         us\n",
       "\n",
       "[74059 rows x 4 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ACER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 11\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mSequential([\n\u001b[0;32m      2\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mInput(shape\u001b[39m=\u001b[39m(\u001b[39m20\u001b[39m, \u001b[39m200\u001b[39m,)),\n\u001b[0;32m      3\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mFlatten(),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m1\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msigmoid\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m ])\n\u001b[0;32m     10\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mBinaryCrossentropy(), metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> 11\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(X_train, y_train, epochs\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m, validation_split\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(20, 200,)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2()),\n",
    "    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2()),\n",
    "    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2()),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(), metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=64, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: trained_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: trained_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('trained_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ACER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:107: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ACER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\utils\\tf_utils.py:585: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loaded_model = tf.keras.models.load_model('trained_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Finished recording.\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Predicted gender: Male\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def record_audio():\n",
    "    CHUNK = 1024\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 2\n",
    "    RATE = 44100\n",
    "    RECORD_SECONDS = 5\n",
    "    WAVE_OUTPUT_FILENAME = \"output.wav\"\n",
    "\n",
    "    audio = pyaudio.PyAudio()\n",
    "\n",
    "    stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                        rate=RATE, input=True,\n",
    "                        frames_per_buffer=CHUNK,\n",
    "                        input_device_index=3)\n",
    "\n",
    "    print(\"Recording...\")\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "\n",
    "    print(\"Finished recording.\")\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n",
    "    wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "\n",
    "    return WAVE_OUTPUT_FILENAME\n",
    "\n",
    "audio_file = record_audio()\n",
    "\n",
    "wf, sr = librosa.load(audio_file)\n",
    "mfcc_wf = librosa.feature.mfcc(y=wf, sr=sr)\n",
    "b = tf.keras.utils.pad_sequences(mfcc_wf, padding='post', maxlen=200)\n",
    "\n",
    "prediction = loaded_model.predict(np.array([b]))\n",
    "\n",
    "if prediction[0][0] > 0.5:\n",
    "    print(\"Predicted gender: Male\")\n",
    "else:\n",
    "    print(\"Predicted gender: Female\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
